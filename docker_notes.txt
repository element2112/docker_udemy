docker notes:

- docker containers are not vms


vms:
- hardware -> host os -> hyper visor (vmware) -> Guest OS -> bins/libs -> application

docker:
- hardware -> host os -> docker daemon -> (bins/libs) -> application

- docker is kind of a package manager for entire applications (kind of)


https://www.tenforums.com/tutorials/164301-how-update-wsl-wsl-2-windows-10-a.html

https://docs.docker.com/engine/install/ubuntu/

- images do not change state. Are built once unless there are changes

- containers == running image
	- OOP example
		- image -> class
		- container -> instance of class
		
- containers are immutable
	- for ex: 
		- running ubuntu image, create a file, exit container
		- run image again, file no longer exists. Therefore container is not changed

- in casual convo docker image and docker repository used interchangably
	- a docker repo consists of multiple images with the same name
		- different versions
		
- docker hub like github for docker images
	- can have personal private or public docker images

- only use images apart of the official repositories managed by docker


BUILDING DOCKER IMAGES

two ways:
	- run docker container -> make changes -> docker commit (saves to new image layer) [wont use this in real world]
	
	- docker file (recipe for creating docker image)
		(think package.json for npm)


CREATE DOCKER file

	- all docker files start with FROM
	- FROM baseimage (use an official base image if possible)
		- FROM scratch ... (an image with no base os)

BUIILDING DOCKER FILE
	- "-t name" allows us to reference the image by what he choose instead of the hash
	
	" docker image build -t web1:1.0 . " (setting version to 1.0)
	
	"docker image ls" (lists all images on our docker host)
	
	"docker image rm web1:1.0" (remove an image)
	
	"docker image tag web1 bs009/web1:latest" (pushing to docker hub)
	
	"docker image rm -f c1b3" (delete an image -f is force. first four characters of image ID)
	
	"docker pull bs009/web1:latest" (pulling image from docker hub)
	

RUNNING IMAGE
 "docker container ls" (showing all running containers)
 
 "docker container run -it -p 5000:5000 -e FLASK_APP=app.py web1"
 
 "docker container ls -a" (see all stopped containers)
 
 "docker container rm condescending_darwin" (remove docker container. its good to not leave a bunch of stopped containers in docker host)
 
 "docker container run -it --rm --name web1container -p 5000:5000 -e FLASK_APP=app.py -d web1" (removes container after it's finished and gives custom name)
 
 "docker container logs -f web1container" (see logs of a container running in background)
 
 "docker container stats" (real time metrics about container)
 
 "docker container run -it --name web1container3 -p 5000 -e FLASK_APP=app.py -d --restart on-failure web1" (running another instance. When only specifying one port, docker auto binds to random port from host)
 
 "docker container stop web1container" (stop docker container)

-t : allows naming of image (-t a_name)
 
-it : allowing docker to enable various linux symbols (like ctrl+c to kill a process, makes terminal interactive)

-p : port ->> bind_port_on_docker_host:bind_port_within_docker_container

-e : environment variable

-d : runs container in background

-f : tails logs in real time

-v : volume ->> path_to_source_files:mount_path_to_container

-itd : adding d to run in background


DOCKER VOLUMES

- every time you make a code change, you would need to stop server, rebuild image, and run container to see live changes using nodemon or something similar
	- docker volumes solves this 
	
- mount source code to the running docker container

"docker container run -it -p 5000:5000 -e FLASH_APP=app.py --rm --name web1 -e FLASK_DEBUG=1 -v $PWD:/app web1"
	- $PWD represents linux command to see current directory
	- /app represents container mount point
	- this is only good for dev mode obviously for production you do not need live changes
	- can also do multiple volume mounts  (not sure yet why you would want to)
	
	
DOCKER DEBUGGING (FOR WINDOWS/MACOS)
- change alpine to slim if there's issues doing docker volumes

"docker container exec -it web1 sh" (connect to already running container (just remoting into it's pc). This is for alpine, if using slim change sh to bash)
"docker container exec -it web1 touch hi.txt" (single exec linux command that exits immediately instead of opening a shell)

- running exec with --user makes sure that all files created are owned by user and not root (mine automatically were owned by my user group)

"docker container exec -it --user "$(id -u):$(id -g)" web1 touch hi.txt" (getting userid and groupid and setting ownership there for new file created in container running alpine)


LINKING MULTIPLE CONTAINERS OVER A NETWORK

internal vs external networks

internal: lan
external: wan

- containers can run on any network

- docker creates a few default networks for us

"docker network ls" (list docker networks)

"docker network inspect bridge" (inspect a network)

running both redis and flash app through same docker bridge network, they can now talk to each other

CREATING OWN BRIDGE NETWORK (to use name )
	- by creating own bridge, docker auto configs DNS and we can connect containers by name

"docker network create --driver bridge firstnetwork" (creating own bridge. can name network whatever we want)

"docker container run --rm -itd -p 6379:6379 --name redis --net firstnetwork redis:3.2-alpine" (linking redis to our created network)

"docker container run --rm -itd -p 5000:5000 -e FLASH_APP=app.py -e FLASH_DEBUG=1 --name web2 -v $PWD:/app --net firstnetwork web2" (linking flask app to our network)

"docker exec web2 ping redis" (can now ping redis by name from web2 instead of by ip address directly)


"bridged" driver: 1 host (can only connect containers on same host)

"overlay" driver: >1 hosts (can connect containers across multiple hosts) 


PERSISTING DATA TO DOCKER HOST (aka not losing data when container stops)

named volume: allow to supply name instead of file path and docker will manage volume in their own volume directory
(perfect for databases)

"docker volume create web2_redis" (can replace web2_redis with any name)

"docker volume ls" (shows list of volumes)

"docker volume inspect web2_redis" (more info on volume)

"docker container run --rm -itd -p 6379:6379 --name redis --net firstnetwork -v web2_redis:/data redis:3.2-alpine" (adding -v with new redis container. /data is redis specific it seems)


"docker exec redis redis-cli SAVE" (having to save the data in memory is redis specific)



SHARING DATA BETWEEN CONTAINERS

in docker file adding "VOLUME ["/app/public"]" says to expose this folder as a volume when the container runs. This folder is not accessable by other containers
	as long as they add "--volumes-from web2" to their flags when running


can automaticcaly see changes from other containers that are accessing the data
	
	
	
optimizing docker files

.dockerignore

(ignoring environment variables, node_modules, etc)

.dockerignore
.git/
.foo/*
**/*.swp
**/*/.txt
# the below adds an exception for a file special.txt
!special.txt

https://medium.com/mozilla-club-bbsr/dockerizing-a-mern-stack-web-application-ebf78babf136
